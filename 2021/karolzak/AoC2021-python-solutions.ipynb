{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Day 1: Sonar Sweep ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Part One ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"day1-input1.txt\", 'r') as file:\n",
    "    inputs = [int(line.replace('\\n', '')) for line in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for i in range(1, len(inputs)):\n",
    "    if inputs[i] > inputs[i-1]:\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Part Two ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for i in range(1, len(inputs)-2):\n",
    "    A = sum(inputs[i-1:i+2])\n",
    "    B = sum(inputs[i:i+3])\n",
    "    if B > A:\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Day 2: Dive! ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Part One ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"day2-input1.txt\", 'r') as file:\n",
    "    inputs = [line.replace('\\n', '') for line in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 0\n",
    "horizontal = 0\n",
    "\n",
    "for direction, v in [move.split() for move in inputs]:\n",
    "    if direction == \"forward\":\n",
    "        horizontal += int(v)\n",
    "    elif direction == \"down\":\n",
    "        depth += int(v)\n",
    "    elif direction == \"up\":\n",
    "        depth -= int(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1507611"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth * horizontal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Part Two ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 0\n",
    "horizontal = 0\n",
    "aim = 0\n",
    "\n",
    "for direction, v in [move.split() for move in inputs]:\n",
    "    if direction == \"forward\":\n",
    "        horizontal += int(v)\n",
    "        depth += aim * int(v)\n",
    "    elif direction == \"down\":\n",
    "        aim += int(v)\n",
    "    elif direction == \"up\":\n",
    "        aim -= int(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1880593125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth * horizontal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Day 3: Binary Diagnostic ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Part One ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"day3-input1.txt\", 'r') as file:\n",
    "    inputs = [line.replace('\\n', '') for line in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cols: 12 Rows: 1000\n"
     ]
    }
   ],
   "source": [
    "cols_num = len(inputs[0])\n",
    "rows_num = len(inputs)\n",
    "print(\"Cols:\", cols_num, \"Rows:\", rows_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "diagnostic_data = np.asarray([int(cell) for row in inputs for cell in row]).reshape(1000,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0],\n",
       "       [0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1],\n",
       "       [1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnostic_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  gamma:  011100101100\n",
      "epsilon:  100011010011\n"
     ]
    }
   ],
   "source": [
    "gamma = ''\n",
    "for i in range(12):\n",
    "    gamma += '1' if diagnostic_data[:,i].sum() > rows_num/2 else '0'\n",
    "epsilon = ''.join(['0' if v == '1' else '1' for v in gamma]) \n",
    "print(\"  gamma: \", gamma)\n",
    "print(\"epsilon: \", epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4147524"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(gamma, 2) * int(epsilon, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Part Two ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_calc(data, col=0, mode='oxygen'):\n",
    "    if len(data) == 1:\n",
    "        return data[0]\n",
    "    # for oxygen:\n",
    "    keep_val =  1 if data[:,col].sum() >= len(data)/2 else 0\n",
    "    if mode == 'co2':\n",
    "        keep_val =  1 - keep_val\n",
    "    data = data[data[:,col] == keep_val]\n",
    "    return rating_calc(data, col+1, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 1 0 0 1 0 0 1 1] [1 0 0 1 1 1 0 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "oxygen_rating = rating_calc(diagnostic_data, mode='oxygen')\n",
    "co2_rating = rating_calc(diagnostic_data, mode='co2')\n",
    "print(oxygen_rating, co2_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert rating to binary string and then convert to int\n",
    "get_rating = lambda x: int(''.join([str(v) for v in x]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3570354"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rating(oxygen_rating) * get_rating(co2_rating) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Day 4: Giant Squid ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Part One ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"day4-numbers.txt\", 'r') as file:\n",
    "    numbers = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [int(number) for number in numbers.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"day4-boards.txt\", 'r') as file:\n",
    "    boards_raw = file.read().split('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "boards = [list(map(int, board.replace('\\n', ' ').replace('  ', ' ').strip().split(' ')))\n",
    "          for board in boards_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bingo(boards):\n",
    "    pattern = np.asarray([True,True,True,True,True])\n",
    "    horizontal = np.where((boards==pattern).all(axis=2))[0]\n",
    "    vertical = np.where((boards==pattern.reshape(5,1)).all(axis=1))[0]\n",
    "    return np.append(horizontal, vertical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_score(bingo, boards_np, boards_np_01, last_number):\n",
    "    winning_board_01 = boards_np_01[bingo]\n",
    "    winning_board_01_inv = np.logical_not(winning_board_01)\n",
    "    winning_board = boards_np[bingo]\n",
    "    final_score = winning_board[winning_board_01_inv].sum() * last_number\n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def play_bingo(boards, get_best=True):\n",
    "    boards_np = np.asarray(boards).reshape(-1,5,5)\n",
    "    boards_np_01 = np.zeros_like(boards_np)\n",
    "    for i in numbers:\n",
    "        boards_np_01 += boards_np == i\n",
    "        bingo = check_bingo(boards_np_01)\n",
    "        if len(bingo) > 0:\n",
    "            last_board_score = calc_score(bingo, boards_np, boards_np_01, i)\n",
    "            if get_best:\n",
    "                print(\"BINGO!!!\")\n",
    "                break;\n",
    "            # set values to something that will prevent these boards from further processing\n",
    "            boards_np_01[bingo] = 0\n",
    "            boards_np[bingo] = -1\n",
    "    return last_board_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BINGO!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31424"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_bingo(boards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Part Two ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23042"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_bingo(boards, get_best=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Day 5: Hydrothermal Venture ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Part One ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"day5-input1.txt\", 'r') as file:\n",
    "    inputs = [line.replace('\\n', '') for line in file.readlines()]\n",
    "    inputs = [line.replace(' -> ', ',').split(',') for line in inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select just horizontal and vertical lines\n",
    "inputs_hor_and_vert = [coords for coords in inputs\n",
    "                      if coords[0]==coords[2] or coords[1]==coords[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def get_range(v1, v2):\n",
    "    pts_range = list(range(min(v1, v2), max(v1, v2) + 1))\n",
    "    if v1 > v2:\n",
    "        # range needs to be in correct order (important for diagonals)\n",
    "        pts_range = list(reversed(pts_range))\n",
    "    return pts_range\n",
    "\n",
    "def line2pts(x1, y1, x2, y2):\n",
    "    x_range = get_range(x1, x2)\n",
    "    y_range = get_range(y1, y2)\n",
    "\n",
    "    if len(x_range) != len(y_range):\n",
    "        # this is for horizontal and vertical lines\n",
    "        pts = list(itertools.product(x_range, y_range))\n",
    "    else:\n",
    "    # for 45 degrees diagonals\n",
    "        pts = zip(x_range, y_range)\n",
    "\n",
    "    return pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def calculate_danger_pts(inputs):\n",
    "    pts_list = []\n",
    "    for coords in inputs:\n",
    "        coords = [int(coord) for coord in coords]\n",
    "        pts_list += line2pts(*coords)\n",
    "\n",
    "    duplicate_pts = [\n",
    "        item for item, count in\n",
    "        collections.Counter(pts_list).items()\n",
    "        if count > 1\n",
    "    ]\n",
    "    return len(duplicate_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5197"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_danger_pts(inputs_hor_and_vert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Part Two ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18605"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_danger_pts(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Day 6: Lanternfish ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Part One ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"day6-input1.txt\", 'r') as file:\n",
    "    inputs = file.read()\n",
    "    # ex: '[1,2,3,4,..]'\n",
    "    inputs = [int(v) for v in inputs.split(',')]\n",
    "    # ex: [1,2,3,4,..]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fish_spawner(input_fish, days):\n",
    "    timers_np = np.asarray(inputs)\n",
    "\n",
    "    for d in range(days):\n",
    "        spawn_mask = timers_np == 0\n",
    "        timers_np -= 1\n",
    "        timers_np[spawn_mask] = 6\n",
    "        timers_np = np.append(\n",
    "            timers_np, \n",
    "            np.full(spawn_mask.sum(), 8))\n",
    "    return len(timers_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394994"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish_spawner(inputs, 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Part Two ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "\n",
    "def fish_spawner_scalable(inputs, days):\n",
    "    # turn inputs into dict of counts\n",
    "    timer_dict = dict(itertools.product(range(9), [0]))\n",
    "    counter = collections.Counter(inputs)\n",
    "    for i, v in counter.items():\n",
    "        timer_dict[i] += v\n",
    "    # ex: { 0: 218, 1: 50, 2: 30, ..., 8: 0}\n",
    "        \n",
    "    for _ in range(days):\n",
    "        # keep number of newborns\n",
    "        newborns = timer_dict[0]\n",
    "        # rotate values to the left in the dict\n",
    "        for i in range(0,8):\n",
    "            timer_dict[i] = timer_dict[i+1]\n",
    "        # add # of fish which spawned new fish to # of fish with timer 6\n",
    "        timer_dict[6] += newborns\n",
    "        # assign newly spawned fish to timer 8\n",
    "        timer_dict[8] = newborns\n",
    "    return sum(timer_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1765974267455"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish_spawner_scalable(inputs, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Day 7: The Treachery of Whales ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Part One ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open(\"day7-input1.txt\", 'r') as file:\n",
    "    inputs = file.read()\n",
    "    # ex: '[1,2,3,4,..]'\n",
    "    inputs = [int(v) for v in inputs.split(',')]\n",
    "    # ex: [1,2,3,4,..]\n",
    "    inputs = np.asarray(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median:  349.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "355592"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median = np.median(inputs)\n",
    "print(\"Median: \", median)\n",
    "np.abs(inputs - round(median)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Part Two ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fuel(distance):\n",
    "    return np.arange(1, distance+1).sum()\n",
    "\n",
    "calc_fuel_vect = np.vectorize(calc_fuel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_usage_sum_list = []\n",
    "for i in range(min(inputs), int(max(inputs))):\n",
    "    distance_arr = np.abs(inputs - round(i))\n",
    "    fuel_usage_arr = calc_fuel_vect(distance_arr)\n",
    "    fuel_usage_sum_list.append(fuel_usage_arr.sum())\n",
    "fuel_usage_sum_list = np.asarray(fuel_usage_sum_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101618069"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuel_usage_sum_list[fuel_usage_sum_list.argmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact using mean should work too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101618069"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = np.mean(inputs)\n",
    "# calc distance arr between crab positions and target position\n",
    "distance_arr = np.abs(inputs - int(mean))\n",
    "# calc fuel usage for each distance (vetorized)\n",
    "fuel_usage_arr = calc_fuel_vect(distance_arr)\n",
    "# sum all fuel used by all crabs\n",
    "fuel_usage_arr.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Day 8: Seven Segment Search ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Part One ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open(\"day8-input1.txt\", 'r') as file:\n",
    "    all_inputs = file.readlines()\n",
    "\n",
    "all_inputs = [line.replace('\\n','').replace(' | ', '|').split('|')\n",
    "          for line in all_inputs]\n",
    "inputs, outputs = map(list, zip(*all_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_easy_digits(output):\n",
    "    easy_digits_lens = [2, 3, 4, 7]\n",
    "    signals = output.split()\n",
    "    easy_digits = [signal for signal in signals\n",
    "                  if len(signal) in easy_digits_lens]\n",
    "    return easy_digits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(get_easy_digits(out)) for out in outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Part Two ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: ['cf'],\n",
       " 3: ['acf'],\n",
       " 4: ['bcdf'],\n",
       " 7: ['abcdefg'],\n",
       " 5: ['acdeg', 'acdfg', 'abdfg'],\n",
       " 6: ['abdefg', 'abcdfg', 'abcefg']}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# digits to ground truth signal\n",
    "digits_sig_gt = {\n",
    "    0: 'abcefg',\n",
    "    1: 'cf',\n",
    "    2: 'acdeg',\n",
    "    3: 'acdfg',\n",
    "    4: 'bcdf',\n",
    "    5: 'abdfg',\n",
    "    6: 'abdefg',\n",
    "    7: 'acf',\n",
    "    8: 'abcdefg',\n",
    "    9: 'abcdfg'\n",
    "}\n",
    "\n",
    "# signal length to potential digits\n",
    "sig_len_2_digits = {\n",
    "    2:[1], 3:[7], 4:[4], 7:[8], 5: [2, 3, 5], 6: [6, 9, 0]\n",
    "}\n",
    "\n",
    "# signal length to possible ground truth signals\n",
    "sig_len_2_gt_sig = dict(\n",
    "    zip(\n",
    "        sig_len_2_digits.keys(),\n",
    "        [[digits_sig_gt[digit] for digit in sig_len_2_digits[length]]\n",
    "         for length in sig_len_2_digits.keys()]\n",
    "    )\n",
    ")\n",
    "sig_len_2_gt_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crack_mapping(signal_dict):\n",
    "    # signal_dict = {'a': 'eda', 'b': 'agcd', 'c': 'ad', 'd': 'agcd', 'e': 'bgefdac', 'f': 'ad', 'g': 'bgefdac'}\n",
    "    temp = [item for item in signal_dict.items() if len(item[1]) <= 2]\n",
    "    # temp = [[('c', 'ad'), ('f', 'ad')]]\n",
    "    gt_sigs, map_sigs = map(list, zip(*temp))\n",
    "    # gt_sigs = ['c', 'f']\n",
    "    # map_sigs = ['ad', 'ad']\n",
    "    map_sigs = np.unique(list(''.join(map_sigs)))\n",
    "    # map_sigs = ['a' 'd']\n",
    "    for mapping in signal_dict.items():\n",
    "        # mapping = ('a', 'eda')\n",
    "        if mapping[0] not in gt_sigs:\n",
    "            sig = mapping[1]\n",
    "            # sig = 'eda'\n",
    "            for c in map_sigs:\n",
    "                sig = sig.replace(c, '')\n",
    "                # sig = 'e'\n",
    "            signal_dict[mapping[0]] = sig\n",
    "    # do recursion until each mapping point to maximum of 2 gt signals\n",
    "    if len(''.join(signal_dict.values())) < 2*len(signal_dict.values()):\n",
    "        return signal_dict\n",
    "    else:\n",
    "        return crack_mapping(signal_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_numbers = []\n",
    "# zip inputs and outputs and iterate\n",
    "for in1, out1 in zip(inputs[:], outputs[:]):\n",
    "    # placeholder for signals decoder\n",
    "    signal_dict = dict(zip('abcdefg', ['' for i in range(7)]))\n",
    "    \n",
    "    # here we join inputs with outputs to analyze them and build correct signal decoder\n",
    "    # we focus only on easiest digits that we can clearly decode based on \n",
    "    # for each signal check length and match it with output digits to get ground truth signalsignal length\n",
    "    signals = get_easy_digits(in1) + get_easy_digits(out1)\n",
    "    for sig in signals:\n",
    "        for segm in digits_sig_gt[sig_len_2_digits[len(sig)][0]]:\n",
    "            if len(signal_dict[segm]) > 1:\n",
    "                signal_dict[segm] = ''.join([i for i in sig if i in signal_dict[segm]])\n",
    "            if len(signal_dict[segm]) == 0:\n",
    "                signal_dict[segm] = sig\n",
    "    signal_dict = crack_mapping(signal_dict)\n",
    "    \n",
    "    err_sig_2_sig_dict = dict(zip('abcdefg', ['' for i in range(7)]))\n",
    "    for pair in [(c, s[0]) for s in signal_dict.items() for c in s[1]]:\n",
    "        err_sig_2_sig_dict[pair[0]] += pair[1]\n",
    "    \n",
    "    out_number = ''\n",
    "    \n",
    "    for o in out1.split():\n",
    "        if len(o) not in [2,3,4,7]:\n",
    "            decoded = [err_sig_2_sig_dict[c] for c in o]\n",
    "            decoded_clean = np.unique(decoded, return_counts=True)\n",
    "            decoded_final = []\n",
    "            for c in zip(*decoded_clean):\n",
    "                if c[1] > 1:\n",
    "                    for k in c[0]:\n",
    "                        decoded_final.append(k)\n",
    "                else:\n",
    "                    decoded_final.append(c[0])\n",
    "            decoded_final = [c for c in decoded_final if len(c) == 1]\n",
    "            for sig, dig in zip(sig_len_2_gt_sig[len(o)], sig_len_2_digits[len(o)]):\n",
    "                if set(decoded_final).issubset(list(sig)):\n",
    "                    out_number += str(dig)\n",
    "                    break\n",
    "        else:\n",
    "            out_number += str(sig_len_2_digits[len(o)][0])\n",
    "\n",
    "    out_numbers.append(int(out_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1041746"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(out_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Day 9: Smoke Basin ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Part One ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 102)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open(\"day9-input1.txt\", 'r') as file:\n",
    "    all_inputs = file.readlines()\n",
    "all_inputs = [line.replace('\\n','') for line in all_inputs]\n",
    "\n",
    "height_map = np.asarray([int(val) for line in all_inputs\n",
    "                         for val in line]\n",
    "                       ).reshape(len(all_inputs), len(all_inputs[0]))\n",
    "# pad with 9 for sliding window\n",
    "height_map = np.pad(height_map, [[1,1],[1,1]], constant_values=9)\n",
    "height_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowest_points = []\n",
    "# sliding window\n",
    "for i in range(1, height_map.shape[0]-1):\n",
    "    for j in range(1, height_map.shape[1]-1):\n",
    "        # take 3x3 slice\n",
    "        local_slice = height_map[j-1:j+2, i-1:i+2]\n",
    "        # if central value is minimum check if it is unique in slice\n",
    "        if local_slice.min() == height_map[j,i]:\n",
    "            # check if minimal value is also unique\n",
    "            values, counts = np.unique(local_slice, return_counts=True)\n",
    "            if counts[0] == 1:\n",
    "                lowest_points.append((j,i))\n",
    "\n",
    "sum([height_map[pt[0],pt[1]] + 1 for pt in lowest_points])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Part Two ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basin_pts(start_point, total_basin_points, height_map):\n",
    "    # recursive function to look for all basin points\n",
    "    # point to check from\n",
    "    x, y = start_point\n",
    "    # need to select points in all adjacent horizontal + vertical directions\n",
    "    pts_to_check = [(x-1,y), (x,y-1), (x+1,y), (x,y+1)]\n",
    "    # then we filter those potential points to exclude 9 and duplicates\n",
    "    new_basin_points = [pt for pt in pts_to_check\n",
    "                        if height_map[pt] != 9 and pt not in total_basin_points]\n",
    "    # if we found new points add them to total points list and continue recursion\n",
    "    if len(new_basin_points) > 0:\n",
    "        total_basin_points += new_basin_points\n",
    "        # we continue recursion for each new basin point found\n",
    "        for pt in new_basin_points:\n",
    "            total_basin_points = get_basin_pts(\n",
    "                pt, total_basin_points, height_map)\n",
    "    # if no new points found, return total basin points\n",
    "    return total_basin_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600104"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_basins = []\n",
    "# iterate through all lowest points\n",
    "for pt in lowest_points:\n",
    "    # get basin points for low point\n",
    "    basin_pts = get_basin_pts(pt, [], height_map)\n",
    "    # add basin sice to collection\n",
    "    all_basins.append(len(basin_pts))\n",
    "\n",
    "# sort basin sizes (largest go last)\n",
    "all_basins.sort()\n",
    "\n",
    "all_basins[-3] * all_basins[-2] * all_basins[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kaggle]",
   "language": "python",
   "name": "conda-env-kaggle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
